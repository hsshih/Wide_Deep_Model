{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViP-uqIV-wvu"
      },
      "source": [
        "## Demo for Deep and Wide Bandits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQh2WlVftITW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from random import random\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur6JrgpIw1zj"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbL9-TQItaOM"
      },
      "source": [
        "import sys\n",
        "## path to wide_deep_bandits.py and toy_problem_wu.py files\n",
        "path = '/content/drive/MyDrive/Fellowship_Deep_and_Wide_Bandit/Wide_and_Deep_Models/'\n",
        "sys.path.append(path)\n",
        "\n",
        "#from contextual_dataset_wu import ContextualDataset\n",
        "from toy_problem_wu import generate_dataframe\n",
        "from wide_deep_bandits import Wide_Deep_Bandits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur_5JBZYImbn"
      },
      "source": [
        "# Toy problem\n",
        "The space-bandits toy_problem divides users/customers into two groups\n",
        "\n",
        "Group 1: age ~25, ARPU ~100, user_id range 0 - 19, best action = 0\n",
        "\n",
        "Group 2: age ~45, ARPU ~50, user_id range 20 - 39, best action = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "G6LhYAIntpaS",
        "outputId": "1f0e794d-b6ac-4994-b0fb-a2e5bd693686"
      },
      "source": [
        "## Get training data from toy_problem\n",
        "n_train_sample = 10000\n",
        "df = generate_dataframe(n_train_sample)\n",
        "context_cols = ['age','ARPU']\n",
        "action_col = ['action']\n",
        "reward_col = ['reward']\n",
        "user_id_col = ['user_id']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ARPU</th>\n",
              "      <th>action</th>\n",
              "      <th>reward</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31.0</td>\n",
              "      <td>100.265699</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.0</td>\n",
              "      <td>18.657117</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.0</td>\n",
              "      <td>100.990283</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.0</td>\n",
              "      <td>93.845837</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57.0</td>\n",
              "      <td>44.111938</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age        ARPU  action  reward  user_id\n",
              "0  31.0  100.265699       1       0       10\n",
              "1  37.0   18.657117       2       0       23\n",
              "2  29.0  100.990283       2       0       16\n",
              "3  23.0   93.845837       0      10       17\n",
              "4  57.0   44.111938       1       0       21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFbc2ubdtx3e",
        "outputId": "fdc50d6c-f17e-4441-e8f4-07c9be8d86e3"
      },
      "source": [
        "num_actions = df[action_col].nunique()[0]\n",
        "num_features = len(context_cols)\n",
        "num_users = df[user_id_col].nunique()[0]\n",
        "print(\"Number of actions:\", num_actions)\n",
        "print(\"Number of features:\", num_features)\n",
        "print(\"Number of users:\", num_users)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of actions: 3\n",
            "Number of features: 2\n",
            "Number of users: 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCpd2ODzIhBa"
      },
      "source": [
        "# Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3VeJoXj27zm",
        "outputId": "95f9e3c6-f730-49a4-83e2-bb2ce234670d"
      },
      "source": [
        "%%time\n",
        "\n",
        "### Train models \n",
        "demo_model_wide = Wide_Deep_Bandits(num_actions, num_features, wide_embed_size=num_users, model_type='wide', num_epochs=10) ## Wide only model\n",
        "demo_model_deep = Wide_Deep_Bandits(num_actions, num_features, wide_embed_size=num_users, model_type='deep', num_epochs=10) ## Deep only model\n",
        "demo_model_wide_deep = Wide_Deep_Bandits(num_actions, num_features, wide_embed_size=num_users, model_type='wide_deep', num_epochs=10) ## Wide + Deep model\n",
        "\n",
        "test_context = df[context_cols].values\n",
        "test_action = df[action_col].values[:,0]\n",
        "test_reward = df[reward_col].values[:,0]\n",
        "test_user_id = df[user_id_col].values[:,0]\n",
        "\n",
        "## Use the 'fit' function to fit a batch of data. \n",
        "## Another option is to use the 'update' function to add one data point at a time. \n",
        "demo_model_wide.fit(test_user_id, test_context,test_action,test_reward)\n",
        "demo_model_deep.fit(test_user_id, test_context,test_action,test_reward)\n",
        "demo_model_wide_deep.fit(test_user_id, test_context,test_action,test_reward)\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.18 s, sys: 4.95 ms, total: 1.19 s\n",
            "Wall time: 1.19 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv42J7tn9Xuh"
      },
      "source": [
        "## Predict Best Action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPAqk6QC4tva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf698e53-de49-4c6e-a6bd-faa35621e516"
      },
      "source": [
        "user_id = torch.tensor(10)\n",
        "context = torch.tensor([25.0, 100.0])\n",
        "\n",
        "## Use the 'action' function to find get the best action predicted by model for a given data point\n",
        "## Another option is to use the 'predict' function to make predictions on a batch of data\n",
        "action_wide = demo_model_wide.action(user_id, context)\n",
        "action_deep = demo_model_deep.action(user_id, context)\n",
        "action_wide_deep = demo_model_wide_deep.action(user_id, context)\n",
        "\n",
        "print(\"Wide model predicts action: \", action_wide)\n",
        "print(\"Deep model predicts action: \", action_deep)\n",
        "print(\"Wide + Deep model predicts action: \", action_wide_deep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wide model predicts action:  0\n",
            "Deep model predicts action:  0\n",
            "Wide + Deep model predicts action:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fellowship_Deep_and_Wide_Bandit/Wide_and_Deep_Models/wide_deep_bandits.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  context = torch.tensor(context).float().to(device)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhk-Bk2m9d3f"
      },
      "source": [
        "## Get Expected Rewards for Each Action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbXzA0tA7sg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f02a4c-b3ad-463e-df88-607a519f899d"
      },
      "source": [
        "expected_values_wide = demo_model_wide.expected_values(user_id, context, multiple_rows=False)\n",
        "expected_values_deep = demo_model_deep.expected_values(user_id, context, multiple_rows=False)\n",
        "expected_values_wide_deep = demo_model_wide_deep.expected_values(user_id, context, multiple_rows=False)\n",
        "\n",
        "print(\"Wide model expected values: \", expected_values_wide)\n",
        "print(\"Deep model expected values: \", expected_values_deep)\n",
        "print(\"Wide + Deep model expected values: \", expected_values_wide_deep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wide model expected values:  tensor([ 8.5194,  2.6094, -0.5079], grad_fn=<SqueezeBackward1>)\n",
            "Deep model expected values:  tensor([9.4291, 0.8213, 5.9998], grad_fn=<SqueezeBackward1>)\n",
            "Wide + Deep model expected values:  tensor([8.4731, 1.7266, 5.3449], grad_fn=<SqueezeBackward1>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fellowship_Deep_and_Wide_Bandit/Wide_and_Deep_Models/wide_deep_bandits.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  context = torch.tensor(context).float().to(device)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}